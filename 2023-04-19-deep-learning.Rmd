## Install and attach packages

```{r}
if(FALSE){
  install.packages(c("data.table", "R.utils", "ggplot2", "torch"))
}
library(data.table)
library(ggplot2)
```

In R one of the biggest strengths is the variety of packages that are
available for different kinds of data analysis. In this tutorial we
use packages:

* `data.table` for reading data from disk, and converting into a
  format useful for visualization.
* `ggplot2` for visualizing the data and results.
* `torch` for machine learning using linear models and neural
  networks.

In R there are two methods for accessing objects which are exported
from packages:

* double-colon syntax, `pkg::fun` means to get `fun` which is exported
  from `pkg`, for example `data.table::fread` is a function for
  reading text data files into R. This is useful for
  teaching/understanding because it is explicit (easy to see which
  package each object comes from), so it should be preferred for most
  use cases.
* We can also use `library(package)` to attach all of the exported
  functions in package. For example after doing `library(data.table)`
  you can just write `fread` (without `data.table::`). This is useful
  for convenience (no need to use the double colon syntax), but it
  hides which package each object comes from, so it should be used
  sparingly.

## Download, read, visualize zip code data

Download zip code image data set.

```{r}
url.vec <- c(
  zip.gz="https://web.stanford.edu/~hastie/ElemStatLearn/datasets/zip.train.gz")
for(f in names(url.vec)){
  u <- url.vec[[f]]
  if(!file.exists(f)){
    download.file(u, f)
  }
}
```

Read data from gzipped plain text (one row per image, columns
separated by spaces) into R as data table.

```{r}
zip.dt <- fread("zip.gz")
```

Convert data table to two multi-dimensional arrays (one for inputs,
one for outputs).

```{r}
zip.feature.dt <- zip.dt[,-1]
n.features <- ncol(zip.feature.dt)
(zip.pixels <- sqrt(n.features))
n.images <- nrow(zip.dt)
zip.X.array <- array(
  unlist(zip.feature.dt),
  c(n.images, 1, zip.pixels, zip.pixels))
str(zip.X.array)
zip.y.array <- array(zip.dt$V1, n.images)
str(zip.y.array)
table(zip.y.array)
```

Visualize one image.

```{r}
image(zip.X.array[1,,,])
```

Below we convert several digits to long/tall form for display. Note
data table syntax below, `by=observation` is like a for loop over
observations, and the data tables returned for each value of
`observation` are combined into a single result table, `zip.some`,
with all of the images.

```{r}
(zip.some <- data.table(observation=1:12)[, {
  data.table(
    label=zip.y.array[observation],
    col=rep(1:zip.pixels, zip.pixels),
    row=rep(1:zip.pixels, each=zip.pixels),
    intensity=as.numeric(zip.X.array[observation,,,]))
}, by=observation])
```

Display images using a panel/facet for each observation.

```{r}
breaks <- c(1, zip.pixels)
ggplot()+
  geom_tile(aes(
    x=col, y=row, fill=intensity),
    data=zip.some)+
  facet_wrap(observation + label ~ ., labeller=label_both)+
  scale_x_continuous(breaks=breaks)+
  scale_y_reverse(breaks=breaks)+
  coord_equal()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  scale_fill_gradient(low="black", high="white")
```

## Convert R data to torch

Torch is a machine learning library which is popular for deep
learning, because it provides automatic differentiation (also known as
auto-grad or automatic gradients), which makes it easy to learn
parameters in deep neural networks. 

* In auto-grad systems, you code the forward calculation (predictions
  and loss),
* using operations for which the gradients of outputs with respect to
  inputs are known (already coded by the creators of the torch
  library),
* so the auto-grad system can use the chain rule (back-propagation) to
  derive the gradients (you do not have to explicitly code the
  gradients, which can be error/bug-prone),
* and the gradients are used for learning (take steps in the negative
  gradient direction to decrease loss).
* For more information about auto-grad, with a demo of how to code a
  simple auto-grad system from scratch in R, and an explanation of how
  to code interactive visualizations of the learning, see Chapter
  18, Neural Networks, in [The animint2
  Manual](https://rcdata.nau.edu/genomic-ml/animint2-manual/Ch18-neural-networks.html).

The popular python module `torch` uses a C++ library `libtorch` under
the hood, which R package `torch` also uses, so it has most of the
same functionality/concepts, and similar naming conventions.

The main data structure in torch is a tensor, which is analogous to
the R multi-dimensional array. Below we convert R arrays to torch
tensors.

```{r}
(zip.y.tensor <- torch::torch_tensor(zip.y.array+1L, torch::torch_long()))
str(zip.y.tensor)
typeof(zip.y.array)
(zip.X.tensor <- torch::torch_tensor(zip.X.array))
str(zip.X.tensor)
typeof(zip.X.array)
```

An important difference between R and torch is that R is very
permissive about types (double/numeric can be used for almost
anything), whereas torch is very strict (single precision float
typically used for inputs, long int used for output).

## Linear model in torch

Before explaining deep learning (neural networks), we first explain
linear models. To implement a linear model in torch, we first need to
flatten each 2d image back to a 1d vector of pixel intensity values,

```{r}
flatten <- torch::nn_flatten()
(zip.X.flat <- flatten(zip.X.tensor))
str(zip.X.flat)
```

A linear model for classification is defined by two kinds of learned
parameters. First, a matrix of real-valued weights, with one row for
each output class, and one column for each input feature. Second, an
intercept/bias, which is a vector of real numbers, one for each output
class.

```{r}
(n.classes <- length(unique(zip.y.array)))
torch::torch_manual_seed(1)#for reproducibility.
linear <- torch::nn_linear(n.features, n.classes)
str(linear$parameters)
```

Calling the linear object with the flattened data as input, yields a
matrix of predicted scores as output (one row per image, one column
per class, larger scores mean more likely to predict that class).

```{r}
(zip.linear.pred <- linear(zip.X.flat))
str(zip.linear.pred)
```

Rather than using flatten and linear operations in separate lines of
code, below we combine them into a sequential object,

```{r}
(sequential <- torch::nn_sequential(flatten, linear))
zip.sequential.pred <- sequential(zip.X.tensor)
str(zip.sequential.pred)
```

What are the current predicted classes? We have not yet done any
learning, and the initialization is random for the weight/bias
parameters, so the initial predictions are very bad, as we see below.

```{r}
pred.class.vec <- apply(zip.sequential.pred, 1, which.max)
zip.y.int <- as.integer(zip.y.tensor)
table(prediction=pred.class.vec, label=zip.y.int)
```

Above is the confusion matrix (predicted classes on rows, true label
on columns, entries are counts of images), and below is the accuracy
rate, which is the diagonal of the confusion matrix.

```{r}
is.correct <- torch::torch_tensor(
  pred.class.vec == zip.y.tensor, torch::torch_float())
(percent.correct <- 100*mean(is.correct))
```

Above is the linear model prediction accuracy at initialization, below
is the baseline featureless model accuracy (always predict most
frequent class label),

```{r}
(zip.y.tab <- table(zip.y.int))
(most.frequent.count <- zip.y.tab[which.max(zip.y.tab)])
(most.frequent.label <- as.integer(names(most.frequent.count)))
100*mean(zip.y.int==most.frequent.label)
```

## Learning in linear model

To improve predictions, we need to use a gradient descent learning
algorithm. First we compute a differentiable loss (cross entropy loss
in this case, multi-class classification), then we compute gradients
using the backward method, then we update parameters by taking steps
in the negative gradient direction. Below we define the loss and optimizer,

```{r}
loss.fun <- torch::nn_cross_entropy_loss()
step.size <- 0.1
optimizer <- torch::optim_sgd(sequential$parameters, lr=step.size)
```

Below we compute predictions and loss,

```{r}
zip.sequential.pred <- sequential(zip.X.tensor)
(loss.tensor <- loss.fun(zip.sequential.pred, zip.y.tensor))
```

Below we set gradients to zero, then call backward to compute and
store gradients of the loss with respect to model parameters.

```{r}
optimizer$zero_grad()
linear$bias$grad
loss.tensor$backward()
linear$bias$grad
```

Below we use the gradients to update the model parameters.

```{r}
linear$bias
optimizer$step()
linear$bias
```

And that's the basic idea of gradient descent learning! Just keep
updating the model parameters until you get good predictions!

## Cross-validation

Keep in mind our goal is generalization, meaning we want to get good
predictions on new data/images that the algorithm was not trained
on. We therefore need to use cross-validation for two purposes:

* testing: hold out some samples as a test set, to evaluate
  predictions after all parameters have been learned on the
  other/train data.
* training: split the train set into subtrain and validation
  sets. Subtrain set is used to compute gradients and update model
  parameters (weights/bias), and validation set is used to learn model
  complexity hyper-parameters (step size, number of epochs, etc).
  
First we need to split the whole data set into train and test, using
cross-validation.

```{r}
cv_list <- function(index.vec, keep, hold.out, n.folds=3){
  uniq.folds <- 1:n.folds
  fold.vec <- sample(rep(uniq.folds, l=length(index.vec)))
  out.list <- list()
  for(fold in uniq.folds){
    is.held.out <- fold.vec==fold
    fold.list <- list()
    fold.list[[hold.out]] <- index.vec[is.held.out]
    fold.list[[keep]] <- index.vec[!is.held.out]
    out.list[[paste(hold.out,"fold",fold)]] <- fold.list
  }
  out.list
}
set.seed(1)
train.test.cv.list <- cv_list(1:n.images, "train", "test")
str(train.test.cv.list)
```

Above we used K-fold cross-validation to create several train/test
splits, represented in R as a list of lists of indices. Below we split
the train set into subtrain and validation sets.

```{r}
test.fold <- 1
train.test.index.list <- train.test.cv.list[[test.fold]]
subtrain.validation.cv.list <- cv_list(
  train.test.index.list$train, "subtrain", "validation")
str(subtrain.validation.cv.list)
```

Below we fix one subtrain/validation split,

```{r}
validation.fold <- 1
subtrain.validation.index.list <- subtrain.validation.cv.list[[validation.fold]]
```

We compute the average loss and gradient over the entire subtrain set below,

```{r}
get_loss <- function(X.tensor, y.tensor, model, index.vec){
  X.subset <- X.tensor[index.vec,,,,drop=FALSE]
  y.subset <- y.tensor[index.vec]
  pred.subset <- model(X.subset)
  loss.fun(pred.subset, y.subset)
}
optimizer$zero_grad()
(subtrain.loss <- get_loss(
  zip.X.tensor,
  zip.y.tensor,
  sequential,
  subtrain.validation.index.list$subtrain))
subtrain.loss$backward()
optimizer$step()
```

Above is the mean loss over the subtrain set, which can be used for
gradients (deterministic optimization). For learning it is more common
to compute gradients with respect to a random sample of
observations/images (stochastic optimization), as below,

```{r}
get_batch_list <- function(index.vec, batch_size=200){
  n_data <- length(index.vec)
  n_batches <- ceiling(n_data / batch_size)
  batch.vec <- sample(rep(1:n_batches,each=batch_size)[1:n_data])
  split(index.vec, batch.vec)
}
big.batches <- get_batch_list(subtrain.validation.index.list$subtrain, 1000)
str(big.batches)
```

After creating the batches above, we use a for loop below to compute
the loss and gradient for each batch.

```{r}
for(batch.number in seq_along(big.batches)){
  batch.indices <- big.batches[[batch.number]]
  batch.loss <- get_loss(
    zip.X.tensor,
    zip.y.tensor,
    sequential,
    batch.indices)
  print(batch.loss)
  optimizer$zero_grad()
  batch.loss$backward()
  optimizer$step()
}
```

We use the function below to implement the same logic as above (take a
step for each subtrain batch).

```{r}
take_steps <- function(subtrain.list, model){
  optimizer <- torch::optim_sgd(model$parameters, lr=step.size)
  batch.list <- get_batch_list(length(subtrain.list$y), batch_size)
  for(batch.number in seq_along(batch.list)){
    batch.indices <- batch.list[[batch.number]]
    batch.loss <- get_loss(subtrain.list, model, batch.indices)
    optimizer$zero_grad()
    batch.loss$backward()
    optimizer$step()
  }
}

num_epochs <- 50
loss.dt.list <- list()
tensor.list <- list()
for(set.name in names(is.set.list)){
  is.set <- is.set.list[[set.name]]
  tensor.list[[set.name]] <- list(
    X=zip.X.tensor[is.set,,,,drop=FALSE],
    y=zip.y.tensor[is.set])
}
linear.model <- torch::nn_sequential(
  torch::nn_flatten(),
  torch::nn_linear(ncol(zip.feature.dt), n.classes))
n.subtrain <- length(tensor.list$subtrain$y)
for(epoch in 1:num_epochs){
  take_steps(tensor.list$subtrain, linear.model)
  torch::with_no_grad({
    for(set in c("subtrain", "validation")){
      set.data <- tensor.list[[set]]
      set.loss <- get_loss(set.data, linear.model)
      loss.dt.list[[paste(test.fold, epoch, set)]] <- print(data.table(
        test.fold, epoch, set, loss=as.numeric(set.loss)))
    }
  })
}
(loss.dt <- rbindlist(loss.dt.list))

min.dt <- loss.dt[, .SD[which.min(loss)], by=set]
gg <- ggplot()+
  ggtitle("Linear model")+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  geom_line(aes(
    epoch, loss, color=set),
    data=loss.dt)+
  geom_point(aes(
    epoch, loss, color=set, shape=point),
    data=data.table(point="min", min.dt))+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
dl <- directlabels::direct.label(gg, "right.polygons")
png(
  "figure-validation-loss-torch-linear.png", 
  width=6, height=4, units="in", res=200)
print(dl)
dev.off()

linear.metrics <- linear.model %>% fit(
  zip.X.array, zip.y.mat,
  batch_size = 100,
  epochs = num_epochs,
  validation_split = 0.2
)
linear.wide <- do.call(data.table, linear.metrics$metrics)
linear.wide[, epoch := 1:.N]
(linear.tall <- nc::capture_melt_single(
  linear.wide,
  set="val_|", function(x)ifelse(x=="val_", "validation", "subtrain"),
  metric="loss|acc"))
linear.min.loss <- linear.tall[metric=="loss", .SD[which.min(value)], by=set]
linear.min.loss[, loss := "min"]

linear.gg <- ggplot()+
  ggtitle("Linear model")+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  geom_line(aes(
    epoch, value, color=set),
    data=linear.tall[metric=="loss"])+
  geom_point(aes(
    epoch, value, color=set, shape=loss),
    data=linear.min.loss)+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
linear.dl <- directlabels::direct.label(linear.gg, "right.polygons")
png("figure-validation-loss-linear.png",
    width=6, height=4, units="in", res=200)
print(linear.dl)
dev.off()

## Deep sparse model.
conv.model <- keras_model_sequential() %>%
  layer_conv_2d(
    input_shape = dim(zip.X.array)[-1],
    filters = 20,
    kernel_size = c(3,3),
    activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = ncol(zip.y.mat), activation = 'softmax')
str(conv.model)
conv.model %>% compile(
  loss = loss_categorical_crossentropy,#for multi-class classification
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
conv.metrics <- conv.model %>% fit(
  zip.X.array, zip.y.mat,
  batch_size = 100,
  epochs = num_epochs,
  validation_split = 0.2
)
conv.wide <- do.call(data.table, conv.metrics$metrics)
conv.wide[, epoch := 1:.N]
(conv.tall <- nc::capture_melt_single(
  conv.wide,
  set="val_|", function(x)ifelse(x=="val_", "validation", "subtrain"),
  metric="loss|acc"))
conv.min.loss <- conv.tall[metric=="loss", .SD[which.min(value)], by=set]
conv.min.loss[, loss := "min"]

conv.gg <- ggplot()+
  ggtitle("Convolutional neural network")+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  geom_line(aes(
    epoch, value, color=set),
    data=conv.tall[metric=="loss"])+
  geom_point(aes(
    epoch, value, color=set, shape=loss),
    data=conv.min.loss)+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
conv.dl <- directlabels::direct.label(conv.gg, "right.polygons")
png("figure-validation-loss-conv.png",
    width=6, height=4, units="in", res=200)
print(conv.dl)
dev.off()

both.tall <- rbind(
  data.table(model="convolutional", conv.tall),
  data.table(model="linear", linear.tall))
both.gg <- ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  facet_grid(. ~ model)+
  geom_line(aes(
    epoch, value, color=set),
    data=both.tall[metric=="loss"])+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
directlabels::direct.label(both.gg, "right.polygons")

## QUIZ 1. purpose of train/subtrain/validation/test
## sets. 2. overfitting/underfitting. 3. data input format for
## ML. 4. cross-validation fold ID / test/train sets.

## deep dense model.
dense.model <- keras_model_sequential() %>%
  layer_flatten(
    input_shape = dim(zip.X.array)[-1]) %>%
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = 100, activation = 'relu') %>%
  layer_dense(units = 100, activation = 'relu') %>%
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = 100, activation = 'relu') %>%   
  layer_dense(units = 100, activation = 'relu') %>% 
  layer_dense(units = ncol(zip.y.mat), activation = 'softmax')
dense.model %>% compile(
  loss = loss_categorical_crossentropy,#for multi-class classification
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
dense.metrics <- dense.model %>% fit(
  zip.X.array, zip.y.mat,
  batch_size = 100,
  epochs = num_epochs,
  validation_split = 0.2
)

dense.wide <- do.call(data.table, dense.metrics$metrics)
dense.wide[, epoch := 1:.N]
(dense.tall <- nc::capture_melt_single(
  dense.wide,
  set="val_|", function(x)ifelse(x=="val_", "validation", "subtrain"),
  metric="loss|acc"))
dense.min.loss <- dense.tall[metric=="loss", .SD[which.min(value)], by=set]
dense.min.loss[, loss := "min"]
dense.gg <- ggplot()+
  ggtitle("Dense (fully connected) neural network with 8 hidden layers")+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  geom_line(aes(
    epoch, value, color=set),
    data=dense.tall[metric=="loss"])+
  geom_point(aes(
    epoch, value, color=set, shape=loss),
    data=dense.min.loss)+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
dense.dl <- directlabels::direct.label(dense.gg, "right.polygons")
png("figure-validation-loss-dense.png",
    width=6, height=4, units="in", res=200)
print(dense.dl)
dev.off()

three.tall <- rbind(
  both.tall,
  data.table(model="dense", dense.tall))
three.gg <- ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0, "lines"))+
  facet_grid(. ~ model)+
  geom_line(aes(
    epoch, value, color=set),
    data=three.tall[metric=="loss"])+
  scale_y_log10("loss value (lower for better predictions)")+
  scale_x_continuous(
    "epoch (gradient descent passes through subtrain data)",
    limits=c(0, num_epochs*1.2),
    breaks=seq(0, num_epochs, by=10))
three.dl <- directlabels::direct.label(three.gg, "right.polygons")
png("figure-validation-loss-three.png",
    width=6, height=4, units="in", res=200)
print(three.gg)
dev.off()
```

## Package versions used

```{r}
sessionInfo()
```
